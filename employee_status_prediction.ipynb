{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Status Prediction\n",
    "\n",
    "This notebook implements binary classification models (SVM and ANN) to predict employee status (0=Active, 1=Left) based on various features.\n",
    "\n",
    "## 1. Data Preprocessing\n",
    "\n",
    "Perform comprehensive preprocessing on the given dataset containing various abnormalities including missing values, outliers, inconsistent formatting, and duplicates. Encode features where applicable, and split the data appropriately for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/meher/Things/FA25 - 5th sem/ML/Lab/terminal/dataset/Group-2 Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Impute missing values\n",
    "# For numerical columns, use median\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, use mode\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Handle negative values in Age and Experience\n",
    "df['Age'] = df['Age'].abs()\n",
    "df['Experience'] = df['Experience'].abs()\n",
    "\n",
    "# Handle outliers (using IQR for Age, Salary, Experience)\n",
    "for col in ['Age', 'Salary', 'Experience']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "\n",
    "# Standardize Education levels\n",
    "education_map = {\n",
    "    'B.S.': 'Bachelor', 'BACHELOR': 'Bachelor', 'Bachelor': 'Bachelor',\n",
    "    'M.S.': 'Master', 'Master': 'Master', 'masters': 'Master',\n",
    "    'H.S.': 'High School', 'High School': 'High School',\n",
    "    'phd': 'PhD', 'PhD': 'PhD'\n",
    "}\n",
    "df['Education'] = df['Education'].map(education_map).fillna('Other')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Encoding and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "df['Education'] = le.fit_transform(df['Education'])\n",
    "df['Department'] = le.fit_transform(df['Department'])\n",
    "\n",
    "# Drop non-numeric/unnecessary columns (like ID or Date if present)\n",
    "# Assuming first column is ID and one column is Date\n",
    "df = df.drop(columns=[df.columns[0], 'Joining Date'], errors='ignore')\n",
    "\n",
    "# Split data\n",
    "X = df.drop('Status', axis=1)\n",
    "y = df['Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine (SVM)\n",
    "\n",
    "Implement SVM for binary classification with GridSearchCV for hyperparameter tuning, exploring different kernels and regularization parameters. Report best parameters and evaluate model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(probability=True), param_grid, refit=True, verbose=1, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "svm_preds = grid.predict(X_test)\n",
    "svm_probs = grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Network (ANN)\n",
    "\n",
    "Build a three-layer Artificial Neural Network using ReLU activation in the hidden layers and sigmoid activation in the output layer. Implement dropout regularization in each hidden layer. Train the model for 50 epochs, plot the training and validation accuracy/loss curves, and evaluate its performance on the test set. Display the complete model architecture summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "ann_probs = model.predict(X_test).flatten()\n",
    "ann_preds = (ann_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(y_test, ann_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the Results\n",
    "\n",
    "Compare SVM and ANN performance by generating classification reports, confusion matrices, and ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, svm_preds, 'SVM Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, ann_preds, 'ANN Confusion Matrix')\n",
    "\n",
    "# ROC Curves\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_probs)\n",
    "fpr_ann, tpr_ann, _ = roc_curve(y_test, ann_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc(fpr_svm, tpr_svm):.2f})')\n",
    "plt.plot(fpr_ann, tpr_ann, label=f'ANN (AUC = {auc(fpr_ann, tpr_ann):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
